# アルゴリズム詳細説明

## ハイブリッドスコアリング方式の詳細

このドキュメントでは、Comprehensive Data Matcherで使用されているマッチングアルゴリズムの詳細を説明します。

## なぜハイブリッド方式なのか

単一のアルゴリズムでは、以下のような異なる種類の表記ゆらぎに同時に対応することが困難です:

### 問題例

1. **文字レベルのゆらぎ**
   - `オーバーサイズ Tシャツ` ↔ `オーバーサイズTシャツ` (スペースの有無)
   - `ケーブルニット セーター` ↔ `ケーブル編みニットセーター` (表現の違い)

2. **語順のゆらぎ**
   - `スリムフィット デニムパンツ` ↔ `デニムパンツ スリムフィット`
   - `白 コットンTシャツ` ↔ `コットンTシャツ 白`

ハイブリッド方式では、これら両方のゆらぎに対応するため、2つのアルゴリズムを組み合わせています。

## 使用アルゴリズム

### 1. レーベンシュタイン類似度

**概要**
- 編集距離（Edit Distance）に基づく類似度計算
- ある文字列を別の文字列に変換するために必要な最小編集回数を計算

**得意なケース**
- 誤字脱字の検出
- 文字の挿入・削除
- 文字の置換

**計算例**

```python
文字列A: "オーバーサイズTシャツ"
文字列B: "オーバーサイズ Tシャツ"

編集操作:
1. スペースを1文字挿入

編集距離 = 1
類似度 = 1 - (編集距離 / max(len(A), len(B)))
      = 1 - (1 / 12)
      = 0.917 (91.7%)
```

**実装詳細**

このツールでは `rapidfuzz` ライブラリの `fuzz.ratio()` 関数を使用しています。

```python
from rapidfuzz import fuzz

score = fuzz.ratio(string1, string2) / 100.0  # 0.0-1.0に正規化
```

### 2. Jaccard係数

**概要**
- 集合の類似度を測定
- 2つの集合の共通要素の割合を計算

**得意なケース**
- 語順の違いの吸収
- 部分一致の検出
- 単語単位での比較

**計算例**

```python
文字列A: "スリムフィット デニムパンツ"
文字列B: "デニムパンツ スリムフィット"

トークン化:
集合A = {"スリムフィット", "デニムパンツ"}
集合B = {"デニムパンツ", "スリムフィット"}

共通部分 = {"スリムフィット", "デニムパンツ"}  # 2要素
和集合   = {"スリムフィット", "デニムパンツ"}  # 2要素

Jaccard係数 = |共通部分| / |和集合|
           = 2 / 2
           = 1.0 (100%)
```

**実装詳細**

```python
import re

def tokenize(s: str) -> set:
    """文字列を単語に分割"""
    tokens = re.split(r'[ 　/]', s)  # スペースとスラッシュで分割
    return set(filter(None, tokens))

def jaccard_score(s1: str, s2: str) -> float:
    tokens1 = tokenize(s1)
    tokens2 = tokenize(s2)
    
    intersection = len(tokens1.intersection(tokens2))
    union = len(tokens1.union(tokens2))
    
    return intersection / union if union > 0 else 0.0
```

## ハイブリッドスコアの計算

### 基本式

```
ハイブリッドスコア = (レーベンシュタイン類似度 × W_lev) + (Jaccard係数 × W_jac)

ここで、W_lev + W_jac = 1.0
```

### デフォルト設定

```python
WEIGHT_LEVENSHTEIN = 0.7  # レーベンシュタインの重み
WEIGHT_JACCARD = 0.3      # Jaccardの重み
```

### 計算例

```python
入力: "スリムフィット デニムパンツ ブルー"
候補: "デニムパンツ ブルー スリムフィット"

レーベンシュタイン類似度 = 0.75
Jaccard係数 = 1.0

ハイブリッドスコア = (0.75 × 0.7) + (1.0 × 0.3)
                 = 0.525 + 0.3
                 = 0.825 (82.5%)
```

## 重みの調整ガイド

### ケース1: 誤字脱字が多い場合

**推奨設定**
```python
WEIGHT_LEVENSHTEIN = 0.8
WEIGHT_JACCARD = 0.2
```

**理由**
- 文字レベルの類似度を重視
- 微妙な表記の違いを検出

**適用例**
- 手入力データの名寄せ
- OCRで読み取ったデータの補正

### ケース2: 語順の違いが多い場合

**推奨設定**
```python
WEIGHT_LEVENSHTEIN = 0.5
WEIGHT_JACCARD = 0.5
```

**理由**
- 単語レベルの一致を重視
- 語順に依存しないマッチング

**適用例**
- 商品名の統一（「白 Tシャツ」vs「Tシャツ 白」）
- アパレル商品の名寄せ（「デニムパンツ スリム」vs「スリム デニムパンツ」）

### ケース3: バランス型（デフォルト）

**推奨設定**
```python
WEIGHT_LEVENSHTEIN = 0.7
WEIGHT_JACCARD = 0.3
```

**理由**
- 文字レベルの類似度を優先しつつ、語順の違いにも対応
- 多くのケースで適切な結果を得られる

## パフォーマンス考察

### 計算量

- **レーベンシュタイン距離**: O(m × n)
  - m, n: 比較する2つの文字列の長さ
  - rapidfuzzライブラリにより高速化

- **Jaccard係数**: O(m + n)
  - m, n: 2つの集合のサイズ
  - 集合演算は高速

### 実測値（参考）

```
データ件数: 1,000件のゆらぎデータ
標準名: 100件
処理時間: 約3-5秒（MacBook Pro, M1チップ）
```

## 前処理の重要性

### NFKC正規化

ハイブリッドスコアリングの前に、NFKC正規化を行うことで以下の違いを吸収します:

```python
入力前:
"オーバーサイズ" (全角)
"ｵｰﾊﾞｰｻｲｽﾞ" (半角カナ)
"Oversize" (英語)

正規化後:
"オーバーサイズ"
"オーバーサイズ"
"Oversize" (英語は変換されない)
```

### 大文字化

比較前に大文字化することで、大文字小文字の違いを吸収します:

```python
"oversize tshirt" → "OVERSIZE TSHIRT"
"Oversize Tshirt" → "OVERSIZE TSHIRT"
"OVERSIZE TSHIRT" → "OVERSIZE TSHIRT"
```

## 今後の改善案

1. **N-gram法の導入**
   - 文字列を固定長の部分文字列に分割
   - より柔軟なマッチングが可能

2. **機械学習による重み最適化**
   - 過去のマッチング結果から最適な重みを学習
   - データセットに応じた自動調整

3. **音素類似度の追加**
   - カタカナ読みの類似度を考慮
   - 「パーカー」vs「パーカ」などに対応

4. **ブランド・商品名辞書の活用**
   - 一般的な商品カテゴリや色名の辞書を参照
   - より正確なマッチング

## 参考文献

- Levenshtein, V. I. (1966). "Binary codes capable of correcting deletions, insertions, and reversals"
- Jaccard, P. (1912). "The distribution of the flora in the alpine zone"
- rapidfuzz documentation: https://github.com/maxbachmann/RapidFuzz

---
